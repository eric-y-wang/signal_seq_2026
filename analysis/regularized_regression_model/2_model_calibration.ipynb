{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1089b574",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Here, we want to determine the best model parameters to maximize inference and generalizability of the model across human and mouse transcriptional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe4bade",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import decoupler as dc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/data1/rudenska/EYW/git_projects/SIG13/functions')\n",
    "import scanpy_custom as scc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c418c9f",
   "metadata": {},
   "source": [
    "# Prepare Calibration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812f651",
   "metadata": {},
   "source": [
    "## SIG14 Import\n",
    "\n",
    "Bulk RNA-seq of 24h activated and rested mouse CD4 T cells stimulated with single and combinatorial cytokine conditions for 6 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c454cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wange7/miniforge3/envs/scanpy_standard2/lib/python3.13/site-packages/anndata/_core/anndata.py:1798: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/wange7/miniforge3/envs/scanpy_standard2/lib/python3.13/functools.py:934: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    }
   ],
   "source": [
    "counts = pd.read_csv('/data1/rudenska/EYW/git_projects/SIG14/processing_outs/count_matrix_umiDeDup_SIG14.csv', index_col=0)\n",
    "feature_names = pd.read_csv('/data1/rudenska/EYW/git_projects/SIG14/processing_outs/featureNames_SIG14.csv', index_col=0)\n",
    "\n",
    "# prepare counts matrix\n",
    "counts_filtered = counts.loc[counts.index.isin(feature_names.index),:]\n",
    "counts_filtered = counts_filtered.merge(feature_names, left_index=True, right_index=True)\n",
    "counts_filtered = counts_filtered.set_index('gene')\n",
    "counts_filtered.drop(columns=['category'], inplace=True)\n",
    "\n",
    "# convert counts into anndata object and preprocess\n",
    "rna = sc.AnnData(counts_filtered.T)\n",
    "rna.var_names_make_unique()\n",
    "sc.pp.normalize_total(rna)\n",
    "sc.pp.log1p(rna)\n",
    "rna.layers['log1p_norm'] = rna.X.copy()\n",
    "\n",
    "# build out obs dataframe\n",
    "obs_df = pd.DataFrame({\"sample\": counts_filtered.columns})\n",
    "obs_df[['ligand1','ligand2','mouse','well','library','project']] = obs_df['sample'].str.split('_', expand=True)\n",
    "obs_df = obs_df.assign(condition=lambda x: x['ligand1'] + '_' + x['ligand2'])\n",
    "rna.obs = rna.obs.merge(obs_df, left_index=True, right_on='sample')\n",
    "\n",
    "# average across treatment conditions\n",
    "rna_pb = sc.get.aggregate(rna, by=['condition','ligand1','ligand2','mouse','well'], func='mean', layer='log1p_norm')\n",
    "rna_pb.layers['log1p_norm'] = rna_pb.layers['mean'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabbc077",
   "metadata": {},
   "source": [
    "## SIG21 Import\n",
    "\n",
    "Bulk RNA-seq of 72h activated and rested human CD4 T cells stimulated with single and combinatorial cytokine conditions for 6 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.read_csv('/data1/rudenska/EYW/git_projects/SIG21/processing_outs/7DZBSH-expression-matrix_processed.csv', index_col=0)\n",
    "feature_names = pd.read_csv('/data1/rudenska/EYW/git_projects/SIG21/processing_outs/7DZBSH-featureNames.csv', index_col=0)\n",
    "\n",
    "# prepare counts matrix\n",
    "counts_filtered = counts.merge(feature_names, left_index=True, right_on='gene_id')\n",
    "counts_filtered = counts_filtered.set_index('gene_name')\n",
    "counts_filtered.drop(columns=['gene_id','gene_biotype'], inplace=True)\n",
    "\n",
    "# convert counts into anndata object and preprocess\n",
    "rna = sc.AnnData(counts_filtered.T)\n",
    "rna.var_names_make_unique()\n",
    "sc.pp.normalize_total(rna)\n",
    "sc.pp.log1p(rna)\n",
    "rna.layers['log1p_norm'] = rna.X.copy()\n",
    "\n",
    "# build out obs dataframe\n",
    "obs_df = pd.DataFrame({\"sample\": counts_filtered.columns})\n",
    "obs_df[['ligand1','ligand2','replicate']] = obs_df['sample'].str.split('_', expand=True)\n",
    "obs_df = obs_df.assign(condition=lambda x: x['ligand1'] + '_' + x['ligand2'])\n",
    "rna.obs = rna.obs.merge(obs_df, left_index=True, right_on='sample')\n",
    "\n",
    "# average across treatment conditions\n",
    "rna_pb = sc.get.aggregate(rna, by=['condition','ligand1','ligand2','replicate'], func='mean', layer='log1p_norm')\n",
    "rna_pb.layers['log1p_norm'] = rna_pb.layers['mean'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c353c2",
   "metadata": {},
   "source": [
    "# Define Model Functions\n",
    "\n",
    "This function performs ridge regression parallelized across threads and returns activity scores (coefficients), chosen alpha values, and r2 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55789f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_single_condition(y_obs, X, alpha_range, n_perms=1000, zscore_coeffs=True):\n",
    "    cv_model = RidgeCV(alphas=alpha_range, fit_intercept=True, cv=5).fit(X, y_obs)\n",
    "    best_alpha, beta_obs, r2_obs = cv_model.alpha_, cv_model.coef_, cv_model.score(X, y_obs)\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    Y_perm_matrix = np.array([rng.permutation(y_obs) for _ in range(n_perms)]).T\n",
    "\n",
    "    perm_model = Ridge(alpha=best_alpha, fit_intercept=True, random_state=67).fit(X, Y_perm_matrix)\n",
    "    beta_perms = perm_model.coef_ \n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        z = (beta_obs - np.mean(beta_perms, axis=0)) / np.std(beta_perms, axis=0) if zscore_coeffs else beta_obs\n",
    "    \n",
    "    return z, r2_obs, best_alpha\n",
    "\n",
    "def calculate_ligand_activity_parallel(X_mat, Y_mat, alpha_range=np.logspace(-1, 3, 100), n_jobs=-1, verbose=0, zscore_coeffs=True):\n",
    "    X = X_mat.values if isinstance(X_mat, pd.DataFrame) else X_mat\n",
    "    Y = Y_mat.values if isinstance(Y_mat, pd.DataFrame) else Y_mat\n",
    "    ligand_names = X_mat.columns if isinstance(X_mat, pd.DataFrame) else np.arange(X.shape[1])\n",
    "    cond_names = Y_mat.columns if isinstance(Y_mat, pd.DataFrame) else np.arange(Y.shape[1])\n",
    "    \n",
    "    results = Parallel(n_jobs=n_jobs, verbose=verbose)(\n",
    "        delayed(_process_single_condition)(Y[:, i], X, alpha_range, zscore_coeffs=zscore_coeffs) for i in range(len(cond_names))\n",
    "    )\n",
    "\n",
    "    zs, r2s, alphas = zip(*results)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        for name, a, r in zip(cond_names, alphas, r2s):\n",
    "            print(f\"Condition: {name} | Chosen Alpha: {a:.5f} | R2: {r:.4f}\")\n",
    "\n",
    "    return pd.DataFrame(dict(zip(cond_names, zs)), index=ligand_names), pd.Series(r2s, index=cond_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba1fda",
   "metadata": {},
   "source": [
    "# Model Activity Scoring\n",
    "\n",
    "Here, we will calculate activity score model outputs across different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcad769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and scale explanatory matrix\n",
    "ligand_scores = pd.read_csv(\"/data1/rudenska/EYW/git_projects/SIG13/analysis_outs/cytosig/SIG13_waggr_scores_explanatory_mat.csv\", index_col=0)\n",
    "ligands_df = ligand_scores.T\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(ligands_df), columns=ligands_df.columns, index=ligands_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476c3a6",
   "metadata": {},
   "source": [
    "## Calculate SIG14 sPCA scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b1657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2436577/2167409987.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  net_50_weighted = net.groupby('source', group_keys=False).apply(lambda x: x.nlargest(50, 'weight'))\n",
      "/tmp/ipykernel_2436577/2167409987.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  net_50_unweighted = net.groupby('source', group_keys=False).apply(lambda x: x.nlargest(50, 'weight')).drop('weight', axis=1)\n"
     ]
    }
   ],
   "source": [
    "# import spca component genes\n",
    "spca_components = pd.read_csv(\"/data1/rudenska/EYW/git_projects/SIG13/analysis_outs/spca/zscore_degs_allLigands_0.1_alpha1.0_sPCA_loadings.csv\")\n",
    "lm_scored = pd.read_csv('/data1/rudenska/EYW/git_projects/SIG13/analysis_outs/spca/lm_scored_zscore_degs_allLigands_0.1_alpha1.0_sPCA_clean.csv')\n",
    "\n",
    "# filter for good components\n",
    "good_comps = lm_scored['component'].unique().tolist()\n",
    "spca_components = spca_components[spca_components['spca_component'].isin(good_comps)]\n",
    "# format for decoupler\n",
    "net = spca_components.rename(columns={'gene':'target',\n",
    "                                      'spca_component':'source',\n",
    "                                      'loading':'weight'})\n",
    "net_50_weighted = net.groupby('source', group_keys=False).apply(lambda x: x.nlargest(50, 'weight'))\n",
    "net_50_unweighted = net.groupby('source', group_keys=False).apply(lambda x: x.nlargest(50, 'weight')).drop('weight', axis=1)\n",
    "net_all_weighted = net.copy()\n",
    "net_all_unweighted = net.drop('weight', axis=1)\n",
    "\n",
    "# define genes used in scoring\n",
    "comp_genes = net['target'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_spca_scores(adata, net, scoring_genes):\n",
    "    # subset to genes used in scoring\n",
    "    adata = adata.copy()\n",
    "    adata_sub = adata[:, adata.var_names.isin(scoring_genes)].copy()\n",
    "    adata_sub.X = adata_sub.layers['log1p_norm']\n",
    "    sc.pp.scale(adata_sub)\n",
    "    \n",
    "    # calculate waggr with no iterations (no pvalues)\n",
    "    dc.mt.waggr(adata_sub, net, tmin=5, times=0)\n",
    "    \n",
    "    # add waggr scores to full anndata\n",
    "    adata.obsm['score_waggr'] = adata_sub.obsm['score_waggr'].copy()\n",
    "\n",
    "    # add waggr scores to metadata\n",
    "    score_df = adata_sub.obsm['score_waggr']\n",
    "    score_df.columns = [f'waggr_{col}' for col in score_df.columns]\n",
    "    adata.obs = pd.concat([adata_sub.obs, score_df], axis=1)\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b9cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_scored_50_weighted = calc_spca_scores(rna_pb, net_50_weighted, comp_genes)\n",
    "rna_scored_50_unweighted = calc_spca_scores(rna_pb, net_50_unweighted, comp_genes)\n",
    "rna_scored_all_weighted = calc_spca_scores(rna_pb, net_all_weighted, comp_genes)\n",
    "rna_scored_all_unweighted = calc_spca_scores(rna_pb, net_all_unweighted, comp_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3907eeb6",
   "metadata": {},
   "source": [
    "## Calculate SIG14 Activity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ridge(adata_scored):\n",
    "    # process y matrix\n",
    "    y_df = (adata_scored.obs.assign(sample=lambda x: x['condition'].astype(str) + \"_\" + x['mouse'].astype(str) + \"_\" + x['well'].astype(str))\n",
    "                   .groupby('sample')[[c for c in adata_scored.obs.columns if c.startswith('waggr_')]]\n",
    "                   .mean()\n",
    "                   .T)\n",
    "    y_df.index = y_df.index.str.replace('waggr_', '')\n",
    "    Y_scaled = pd.DataFrame(scaler.fit_transform(y_df), columns=y_df.columns, index=y_df.index)\n",
    "    \n",
    "    # calculate ligand activity scores\n",
    "    activity_scores, r2_scores = calculate_ligand_activity_parallel(X_scaled, Y_scaled, verbose=False,\n",
    "                                                                   alpha_range=np.logspace(-1, 3, 100))\n",
    "    activity_scores = activity_scores.T.reset_index(names='sample')\n",
    "\n",
    "    # calculate ligand activity scores\n",
    "    activity_scores_coeff, r2_scores_coeff = calculate_ligand_activity_parallel(X_scaled, Y_scaled, verbose=False,\n",
    "                                                                   alpha_range=np.logspace(-1, 3, 100),\n",
    "                                                                   zscore_coeffs=False)\n",
    "    activity_scores_coeff = activity_scores_coeff.T.reset_index(names='sample')\n",
    "    \n",
    "    return activity_scores, r2_scores, activity_scores_coeff, r2_scores_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate activity scores\n",
    "activity_zscore_ridge_50_unweighted, fit_zscore_ridge_50_unweighted, activity_coeff_ridge_50_unweighted, fit_coeff_ridge_50_unweighted = score_ridge(rna_scored_50_unweighted)\n",
    "activity_zscore_ridge_50_weighted, fit_zscore_ridge_50_weighted, activity_coeff_ridge_50_weighted, fit_coeff_ridge_50_weighted = score_ridge(rna_scored_50_weighted)\n",
    "activity_zscore_ridge_all_unweighted, fit_zscore_ridge_all_unweighted, activity_coeff_ridge_all_unweighted, fit_coeff_ridge_all_unweighted = score_ridge(rna_scored_all_unweighted)\n",
    "activity_zscore_ridge_all_weighted, fit_zscore_ridge_all_weighted, activity_coeff_ridge_all_weighted, fit_coeff_ridge_all_weighted = score_ridge(rna_scored_all_weighted)\n",
    "\n",
    "# concatenate all activity scores\n",
    "activity_list = [\n",
    "    activity_zscore_ridge_50_unweighted,\n",
    "    activity_zscore_ridge_50_weighted,\n",
    "    activity_zscore_ridge_all_unweighted,\n",
    "    activity_zscore_ridge_all_weighted,\n",
    "    activity_coeff_ridge_50_unweighted,\n",
    "    activity_coeff_ridge_50_weighted,\n",
    "    activity_coeff_ridge_all_unweighted,\n",
    "    activity_coeff_ridge_all_weighted]\n",
    "r2_list = [\n",
    "    fit_zscore_ridge_50_unweighted,\n",
    "    fit_zscore_ridge_50_weighted,\n",
    "    fit_zscore_ridge_all_unweighted,\n",
    "    fit_zscore_ridge_all_weighted,\n",
    "    fit_coeff_ridge_50_unweighted,\n",
    "    fit_coeff_ridge_50_weighted,\n",
    "    fit_coeff_ridge_all_unweighted,\n",
    "    fit_coeff_ridge_all_weighted]\n",
    "activity_combined = pd.concat([\n",
    "    df.assign(model=name) for df, name in zip(\n",
    "        activity_list,\n",
    "        ['ridge_zscore_50_unweighted', 'ridge_zscore_50_weighted', 'ridge_zscore_all_unweighted', 'ridge_zscore_all_weighted',\n",
    "         'ridge_coeff_50_unweighted', 'ridge_coeff_50_weighted', 'ridge_coeff_all_unweighted', 'ridge_coeff_all_weighted']\n",
    "    )\n",
    "], ignore_index=True)\n",
    "\n",
    "# Concatenate all R2 scores\n",
    "r2_combined = pd.concat([\n",
    "    pd.DataFrame({'sample': r2.index, 'r2_score': r2.values, 'model': name})\n",
    "    for r2, name in zip(\n",
    "        r2_list,\n",
    "        ['ridge_zscore_50_unweighted', 'ridge_zscore_50_weighted', 'ridge_zscore_all_unweighted', 'ridge_zscore_all_weighted',\n",
    "         'ridge_coeff_50_unweighted', 'ridge_coeff_50_weighted', 'ridge_coeff_all_unweighted', 'ridge_coeff_all_weighted']\n",
    "    )\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export scores\n",
    "# activity_combined.to_csv('/data1/rudenska/EYW/git_projects/SIG13/analysis_outs/cytosig/model_optimization/activity_combined_SIG14.csv', index=False)\n",
    "# r2_combined.to_csv('/data1/rudenska/EYW/git_projects/SIG13/analysis_outs/cytosig/model_optimization/r2_combined_SIG14.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b64b15",
   "metadata": {},
   "source": [
    "## Calculate SIG21 sPCA scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167975fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spca_components = pd.read_csv(\"/data1/rudenska/EYW/git_projects/SIG13/analysis_outs/spca/zscore_degs_allLigands_0.1_alpha1.0_sPCA_loadings.csv\")\n",
    "lm_scored = pd.read_csv('/data1/rudenska/EYW/git_projects/SIG13/analysis_outs/spca/lm_scored_zscore_degs_allLigands_0.1_alpha1.0_sPCA_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df9aad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3943580/1096132307.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  net_50_weighted = net.groupby('source', group_keys=False).apply(lambda x: x.nlargest(50, 'weight'))\n",
      "/tmp/ipykernel_3943580/1096132307.py:15: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  net_50_unweighted = net.groupby('source', group_keys=False).apply(lambda x: x.nlargest(50, 'weight')).drop('weight', axis=1)\n"
     ]
    }
   ],
   "source": [
    "# filter for good components\n",
    "good_comps = lm_scored['component'].unique().tolist()\n",
    "spca_components = spca_components[spca_components['spca_component'].isin(good_comps)]\n",
    "# format for decoupler\n",
    "net = spca_components.rename(columns={'gene':'target',\n",
    "                                      'spca_component':'source',\n",
    "                                      'loading':'weight'})\n",
    "# convert to human genes\n",
    "net = scc.convert_mouse_genes_to_human(net,'target')\n",
    "net.drop('target', axis=1, inplace=True)\n",
    "net.rename(columns={'human_gene':'target'}, inplace=True)\n",
    "net.drop_duplicates(subset=['source', 'target'], inplace=True)\n",
    "\n",
    "net_50_weighted = net.groupby('source', group_keys=False).apply(lambda x: x.nlargest(50, 'weight'))\n",
    "net_50_unweighted = net.groupby('source', group_keys=False).apply(lambda x: x.nlargest(50, 'weight')).drop('weight', axis=1)\n",
    "net_all_weighted = net.copy()\n",
    "net_all_unweighted = net.drop('weight', axis=1)\n",
    "\n",
    "# define genes used in scoring\n",
    "comp_genes = net['target'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ef255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_spca_scores(adata, net, scoring_genes):\n",
    "    # subset to genes used in scoring\n",
    "    adata = adata.copy()\n",
    "    adata_sub = adata[:, adata.var_names.isin(scoring_genes)].copy()\n",
    "    adata_sub.X = adata_sub.layers['log1p_norm']\n",
    "    sc.pp.scale(adata_sub)\n",
    "    \n",
    "    # calculate waggr with no iterations (no pvalues)\n",
    "    dc.mt.waggr(adata_sub, net, tmin=5, times=0)\n",
    "    \n",
    "    # add waggr scores to full anndata\n",
    "    adata.obsm['score_waggr'] = adata_sub.obsm['score_waggr'].copy()\n",
    "\n",
    "    # add waggr scores to metadata\n",
    "    score_df = adata_sub.obsm['score_waggr']\n",
    "    score_df.columns = [f'waggr_{col}' for col in score_df.columns]\n",
    "    adata.obs = pd.concat([adata_sub.obs, score_df], axis=1)\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b4c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_scored_50_weighted = calc_spca_scores(rna_pb, net_50_weighted, comp_genes)\n",
    "rna_scored_50_unweighted = calc_spca_scores(rna_pb, net_50_unweighted, comp_genes)\n",
    "rna_scored_all_weighted = calc_spca_scores(rna_pb, net_all_weighted, comp_genes)\n",
    "rna_scored_all_unweighted = calc_spca_scores(rna_pb, net_all_unweighted, comp_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59781e",
   "metadata": {},
   "source": [
    "# Calculate SIG21 Activity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0313b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ridge(adata_scored):\n",
    "    # process y matrix\n",
    "    y_df = (adata_scored.obs.assign(sample=lambda x: x['condition'].astype(str) + \"_\" + x['replicate'].astype(str))\n",
    "                   .groupby('sample')[[c for c in adata_scored.obs.columns if c.startswith('waggr_')]]\n",
    "                   .mean()\n",
    "                   .T)\n",
    "    y_df.index = y_df.index.str.replace('waggr_', '')\n",
    "    Y_scaled = pd.DataFrame(scaler.fit_transform(y_df), columns=y_df.columns, index=y_df.index)\n",
    "    \n",
    "    # calculate ligand activity scores\n",
    "    activity_scores, r2_scores = calculate_ligand_activity_parallel(X_scaled, Y_scaled, verbose=False,\n",
    "                                                                   alpha_range=np.logspace(-1, 3, 100))\n",
    "    activity_scores = activity_scores.T.reset_index(names='sample')\n",
    "\n",
    "    # calculate ligand activity scores\n",
    "    activity_scores_coeff, r2_scores_coeff = calculate_ligand_activity_parallel(X_scaled, Y_scaled, verbose=False,\n",
    "                                                                   alpha_range=np.logspace(-1, 3, 100),\n",
    "                                                                   zscore_coeffs=False)\n",
    "    activity_scores_coeff = activity_scores_coeff.T.reset_index(names='sample')\n",
    "    \n",
    "    return activity_scores, r2_scores, activity_scores_coeff, r2_scores_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff329095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate activity scores\n",
    "activity_zscore_ridge_50_unweighted, fit_zscore_ridge_50_unweighted, activity_coeff_ridge_50_unweighted, fit_coeff_ridge_50_unweighted = score_ridge(rna_scored_50_unweighted)\n",
    "activity_zscore_ridge_50_weighted, fit_zscore_ridge_50_weighted, activity_coeff_ridge_50_weighted, fit_coeff_ridge_50_weighted = score_ridge(rna_scored_50_weighted)\n",
    "activity_zscore_ridge_all_unweighted, fit_zscore_ridge_all_unweighted, activity_coeff_ridge_all_unweighted, fit_coeff_ridge_all_unweighted = score_ridge(rna_scored_all_unweighted)\n",
    "activity_zscore_ridge_all_weighted, fit_zscore_ridge_all_weighted, activity_coeff_ridge_all_weighted, fit_coeff_ridge_all_weighted = score_ridge(rna_scored_all_weighted)\n",
    "\n",
    "# concatenate all activity scores\n",
    "activity_list = [\n",
    "    activity_zscore_ridge_50_unweighted,\n",
    "    activity_zscore_ridge_50_weighted,\n",
    "    activity_zscore_ridge_all_unweighted,\n",
    "    activity_zscore_ridge_all_weighted,\n",
    "    activity_coeff_ridge_50_unweighted,\n",
    "    activity_coeff_ridge_50_weighted,\n",
    "    activity_coeff_ridge_all_unweighted,\n",
    "    activity_coeff_ridge_all_weighted]\n",
    "r2_list = [\n",
    "    fit_zscore_ridge_50_unweighted,\n",
    "    fit_zscore_ridge_50_weighted,\n",
    "    fit_zscore_ridge_all_unweighted,\n",
    "    fit_zscore_ridge_all_weighted,\n",
    "    fit_coeff_ridge_50_unweighted,\n",
    "    fit_coeff_ridge_50_weighted,\n",
    "    fit_coeff_ridge_all_unweighted,\n",
    "    fit_coeff_ridge_all_weighted]\n",
    "activity_combined = pd.concat([\n",
    "    df.assign(model=name) for df, name in zip(\n",
    "        activity_list,\n",
    "        ['ridge_zscore_50_unweighted', 'ridge_zscore_50_weighted', 'ridge_zscore_all_unweighted', 'ridge_zscore_all_weighted',\n",
    "         'ridge_coeff_50_unweighted', 'ridge_coeff_50_weighted', 'ridge_coeff_all_unweighted', 'ridge_coeff_all_weighted']\n",
    "    )\n",
    "], ignore_index=True)\n",
    "\n",
    "# Concatenate all R2 scores\n",
    "r2_combined = pd.concat([\n",
    "    pd.DataFrame({'sample': r2.index, 'r2_score': r2.values, 'model': name})\n",
    "    for r2, name in zip(\n",
    "        r2_list,\n",
    "        ['ridge_zscore_50_unweighted', 'ridge_zscore_50_weighted', 'ridge_zscore_all_unweighted', 'ridge_zscore_all_weighted',\n",
    "         'ridge_coeff_50_unweighted', 'ridge_coeff_50_weighted', 'ridge_coeff_all_unweighted', 'ridge_coeff_all_weighted']\n",
    "    )\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed78b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "# activity_combined.to_csv('/data1/rudenska/EYW/git_projects/SIG13/analysis_outs/cytosig/model_optimization/activity_combined_SIG21.csv', index=False)\n",
    "# r2_combined.to_csv('/data1/rudenska/EYW/git_projects/SIG13/analysis_outs/cytosig/model_optimization/r2_combined_SIG21.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy_standard2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
